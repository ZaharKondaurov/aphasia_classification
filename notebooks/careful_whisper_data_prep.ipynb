{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-07T13:21:23.900887Z",
     "start_time": "2025-08-07T13:21:16.531661Z"
    }
   },
   "source": [
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import hub\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, balanced_accuracy_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import scipy\n",
    "\n",
    "from src.utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset, Dataset, Audio\n",
    "import librosa\n",
    "\n",
    "from models.cnn import MobileNet\n",
    "from models.CarefulWhisper import CarefulWhisper\n",
    "\n",
    "from flaml import AutoML"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakhar/aphasia_classification/models/CarefulWhisper.py:171: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  process_text = re.sub(\"[^\\w\\s]+\", \" \", process_text)\n",
      "2025-08-07 16:21:21.062852: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-07 16:21:21.149247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754572881.189939   11906 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754572881.205302   11906 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-07 16:21:21.296972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:21:23.908Z",
     "start_time": "2025-08-07T13:21:23.901976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 1984\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(SEED)"
   ],
   "id": "36978642e336b373",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7c79a0539a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:21:23.923647Z",
     "start_time": "2025-08-07T13:21:23.909751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = os.path.join('..', 'data')\n",
    "VOICES_DIR = os.path.join(DATA_DIR, 'Voices_wav')\n",
    "APHASIA_DIR = os.path.join(VOICES_DIR, 'Aphasia')\n",
    "NORM_DIR = os.path.join(VOICES_DIR, 'Norm')\n",
    "\n",
    "# dataset_train = AphasiaDatasetWaveform(os.path.join(DATA_DIR, \"train_filenames_mc.csv\"), VOICES_DIR, target_sample_rate=16_000, file_format=\"wav\")\n",
    "# dataset_val = AphasiaDatasetWaveform(os.path.join(DATA_DIR, \"val_filenames_mc.csv\"), VOICES_DIR, target_sample_rate=16_000, file_format=\"wav\")\n",
    "# dataset_test = AphasiaDatasetWaveform(os.path.join(DATA_DIR, \"test_filenames_mc.csv\"), VOICES_DIR, target_sample_rate=16_000, file_format=\"wav\")"
   ],
   "id": "64bcc426ef3d0cad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:21:38.660819Z",
     "start_time": "2025-08-07T13:21:23.925664Z"
    }
   },
   "cell_type": "code",
   "source": "model = CarefulWhisper(\"cuda\")",
   "id": "bb815566d8bc2d41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:21:38.670543Z",
     "start_time": "2025-08-07T13:21:38.661477Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_train = pd.read_csv(os.path.join(DATA_DIR, 'train_filenames_mc.csv'))",
   "id": "7c75d25714514f50",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T16:31:28.788846Z",
     "start_time": "2025-08-07T13:21:38.671778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = []\n",
    "\n",
    "for ind, x in tqdm(dataset_train.iterrows()):\n",
    "    if x[\"label\"] == 0:\n",
    "        file_path = os.path.join(NORM_DIR, x[\"file_name\"])\n",
    "    else:\n",
    "        file_path = os.path.join(APHASIA_DIR, x[\"file_name\"])\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    if sample_rate != 16_000:\n",
    "        resampler = Resample(sample_rate, 16_000)\n",
    "        waveform = resampler(waveform)\n",
    "    waveform = waveform[..., :16_000 * 20]\n",
    "    output = model(waveform).squeeze()\n",
    "    train_data.append((output, x[\"label\"]))"
   ],
   "id": "8f3e69472746cc4e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "10it [04:04, 23.67s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "281it [1:50:28, 23.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "485it [3:09:50, 23.48s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T16:31:28.948110Z",
     "start_time": "2025-08-07T16:31:28.943815Z"
    }
   },
   "cell_type": "code",
   "source": "train_data_np = np.array([np.concatenate((arr, [num])) for arr, num in train_data])",
   "id": "95008bd6554ec4b6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T16:31:28.958514Z",
     "start_time": "2025-08-07T16:31:28.948874Z"
    }
   },
   "cell_type": "code",
   "source": "np.save('train_data_careful_whisper_mc.npy', train_data_np)",
   "id": "fe1d28946c44e85f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T17:29:27.809461Z",
     "start_time": "2025-08-07T16:31:28.959290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_val = pd.read_csv(os.path.join(DATA_DIR, 'val_filenames_mc.csv'))\n",
    "val_data = []\n",
    "\n",
    "for ind, x in tqdm(dataset_val.iterrows()):\n",
    "    if x[\"label\"] == 0:\n",
    "        file_path = os.path.join(NORM_DIR, x[\"file_name\"])\n",
    "    else:\n",
    "        file_path = os.path.join(APHASIA_DIR, x[\"file_name\"])\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    if sample_rate != 16_000:\n",
    "        resampler = Resample(sample_rate, 16_000)\n",
    "        waveform = resampler(waveform)\n",
    "    waveform = waveform[..., :16_000 * 20]\n",
    "    output = model(waveform).squeeze()\n",
    "    val_data.append((output, x[\"label\"]))"
   ],
   "id": "d900529dd982afb7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [57:58, 23.35s/it]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T17:29:27.816743Z",
     "start_time": "2025-08-07T17:29:27.811474Z"
    }
   },
   "cell_type": "code",
   "source": "val_data_np = np.array([np.concatenate((arr, [num])) for arr, num in val_data])",
   "id": "b1d1300721f4edba",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T17:29:27.832146Z",
     "start_time": "2025-08-07T17:29:27.817605Z"
    }
   },
   "cell_type": "code",
   "source": "np.save('val_data_careful_whisper_mc.npy', val_data_np)",
   "id": "a53966a8d5864f4f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T18:23:57.208138Z",
     "start_time": "2025-08-07T17:29:27.833559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_test = pd.read_csv(os.path.join(DATA_DIR, 'test_filenames_mc.csv'))\n",
    "test_data = []\n",
    "\n",
    "for ind, x in tqdm(dataset_test.iterrows()):\n",
    "    if x[\"label\"] == 0:\n",
    "        file_path = os.path.join(NORM_DIR, x[\"file_name\"])\n",
    "    else:\n",
    "        file_path = os.path.join(APHASIA_DIR, x[\"file_name\"])\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "    if sample_rate != 16_000:\n",
    "        resampler = Resample(sample_rate, 16_000)\n",
    "        waveform = resampler(waveform)\n",
    "    waveform = waveform[..., :16_000 * 20]\n",
    "    output = model(waveform).squeeze()\n",
    "    test_data.append((output, x[\"label\"]))"
   ],
   "id": "cf7054184bb1412d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [54:29, 23.35s/it]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T18:23:57.213701Z",
     "start_time": "2025-08-07T18:23:57.210245Z"
    }
   },
   "cell_type": "code",
   "source": "test_data_np = np.array([np.concatenate((arr, [num])) for arr, num in test_data])",
   "id": "ab80fe4f5df5f0b6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T18:23:57.226695Z",
     "start_time": "2025-08-07T18:23:57.214413Z"
    }
   },
   "cell_type": "code",
   "source": "np.save('test_data_careful_whisper_mc.npy', test_data_np)",
   "id": "d004940c43ca2559",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T18:23:57.229404Z",
     "start_time": "2025-08-07T18:23:57.227583Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4c808aab85872ca0",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
